{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "header"
   },
   "source": [
    "# DiffSTOCK India - Training on Google Colab\n",
    "\n",
    "This notebook:\n",
    "1. Clones the DiffSTOCK repository\n",
    "2. Installs dependencies\n",
    "3. Downloads/loads dataset\n",
    "4. Trains the model\n",
    "5. Saves checkpoints and metrics\n",
    "6. Performs validation and testing\n",
    "7. Generates comprehensive evaluation reports\n",
    "\n",
    "**Runtime**: GPU recommended (training takes 2-4 hours on GPU, 12-20 hours on CPU)\n",
    "\n",
    "**Author**: Siddhartha Koppaka  \n",
    "**Model**: DiffSTOCK (ICASSP 2024) adapted for Indian markets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "check_gpu"
   },
   "outputs": [],
   "source": [
    "# Check if GPU is available\n",
    "import torch\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mount_drive"
   },
   "outputs": [],
   "source": [
    "# Mount Google Drive to save outputs\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Create output directory in Google Drive\n",
    "import os\n",
    "OUTPUT_DIR = '/content/drive/MyDrive/DiffSTOCK_Outputs'\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "print(f\"Outputs will be saved to: {OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "clone_repo"
   },
   "source": [
    "## Clone Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "clone"
   },
   "outputs": [],
   "source": "# Clone the repository\n!git clone https://github.com/SiddarthaKoppaka/stock_model.git\n%cd stock_model/diffstock_india\n!ls -la"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "install_deps"
   },
   "source": [
    "## Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install"
   },
   "outputs": [],
   "source": [
    "# Install requirements\n",
    "!pip install -r requirements.txt -q\n",
    "\n",
    "# Verify installation\n",
    "!python verify_installation.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "data_section"
   },
   "source": [
    "## Data Setup\n",
    "\n",
    "### Option 1: Upload Pre-downloaded Dataset\n",
    "If you have already scraped the data locally, upload it here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "upload_data"
   },
   "outputs": [],
   "source": [
    "# Upload dataset files\n",
    "from google.colab import files\n",
    "import os\n",
    "\n",
    "print(\"Please upload the following files from your local machine:\")\n",
    "print(\"1. nifty500_10yr.npz (from data/dataset/)\")\n",
    "print(\"2. relation_matrices.npz (from data/dataset/)\")\n",
    "print(\"\\nUploading...\")\n",
    "\n",
    "uploaded = files.upload()\n",
    "\n",
    "# Move files to correct locations\n",
    "!mkdir -p data/dataset\n",
    "for filename in uploaded.keys():\n",
    "    !mv {filename} data/dataset/\n",
    "    print(f\"Moved {filename} to data/dataset/\")\n",
    "\n",
    "print(\"\\nDataset files uploaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "### ⚠️ CRITICAL: Rebuild Dataset with 16 Features\n\n**The code was updated to use 16 features instead of 15.**\n\nIf you uploaded an old dataset or scraped data before this update, you MUST rebuild the dataset by running the cell below.",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "data_option2"
   },
   "source": [
    "### Option 2: Download Data on Colab (Slow - 30-60 minutes)\n",
    "**Warning**: This will take 30-60 minutes. Only use if you don't have pre-downloaded data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "download_data"
   },
   "outputs": [],
   "source": [
    "# Uncomment to run data scraping on Colab (slow!)\n",
    "# !python scripts/run_scrape.py\n",
    "\n",
    "# Build dataset\n",
    "# !python -c \"from src.data.dataset_builder import build_dataset; build_dataset(run_scraping=False)\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "verify_data"
   },
   "source": [
    "## Verify Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "check_data"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Load and inspect dataset\n",
    "data = np.load('data/dataset/nifty500_10yr.npz', allow_pickle=True)\n",
    "\n",
    "print(\"Dataset Contents:\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Train samples: {len(data['X_train'])}\")\n",
    "print(f\"Val samples: {len(data['X_val'])}\")\n",
    "print(f\"Test samples: {len(data['X_test'])}\")\n",
    "print(f\"\\nStocks: {len(data['stock_symbols'])}\")\n",
    "print(f\"Features: {len(data['feature_names'])}\")\n",
    "print(f\"\\nX_train shape: {data['X_train'].shape}\")\n",
    "print(f\"y_train shape: {data['y_train'].shape}\")\n",
    "\n",
    "# Load relation matrices\n",
    "relations = np.load('data/dataset/relation_matrices.npz')\n",
    "print(f\"\\nRelation mask density: {relations['R_mask'].mean():.2%}\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "config_section"
   },
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "load_config"
   },
   "outputs": [],
   "source": "import yaml\nfrom pathlib import Path\n\n# Load config\nwith open('config/config.yaml', 'r') as f:\n    config = yaml.safe_load(f)\n\n# Update paths for Colab\nconfig['paths']['root'] = '/content/stock_model/diffstock_india'\nconfig['paths']['checkpoints'] = 'checkpoints'\nconfig['paths']['logs'] = 'logs'\nconfig['paths']['results'] = 'results'\n\n# Create directories\nfor path in ['checkpoints', 'logs', 'results']:\n    os.makedirs(path, exist_ok=True)\n\nprint(\"Configuration:\")\nprint(\"=\" * 80)\nprint(f\"Model: d_model={config['model']['d_model']}, T={config['model']['diffusion_T']}\")\nprint(f\"Training: epochs={config['training']['max_epochs']}, batch_size={config['training']['batch_size']}\")\nprint(f\"Learning rate: {config['training']['learning_rate']}\")\nprint(\"=\" * 80)"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "model_section"
   },
   "source": [
    "## Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "create_model"
   },
   "outputs": [],
   "source": "import sys\nsys.path.insert(0, '/content/stock_model/diffstock_india')\n\nfrom src.model.diffstock import create_diffstock_model\nfrom src.utils.seed import set_seed\nfrom src.utils.logger import setup_logger\n\n# Set seed for reproducibility\nset_seed(config['seed'])\n\n# Setup logger\nsetup_logger(log_dir=Path('logs'), log_level='INFO')\n\n# Create model\nn_stocks = len(data['stock_symbols'])\nmodel = create_diffstock_model(config, n_stocks)\n\n# Print model summary\nmodel.print_model_summary()\n\n# Move to GPU if available\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel = model.to(device)\nprint(f\"\\nModel moved to device: {device}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "training_section"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "setup_trainer"
   },
   "outputs": [],
   "source": [
    "from src.training.trainer import DiffSTOCKTrainer\n",
    "\n",
    "# Load relation mask\n",
    "R_mask = torch.FloatTensor(relations['R_mask'])\n",
    "\n",
    "# Create trainer\n",
    "trainer = DiffSTOCKTrainer(\n",
    "    model=model,\n",
    "    config=config,\n",
    "    R_mask=R_mask,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "print(\"Trainer initialized!\")\n",
    "print(f\"Device: {trainer.device}\")\n",
    "print(f\"Mixed precision: {trainer.use_amp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "train_model"
   },
   "outputs": [],
   "source": [
    "# Train the model\n",
    "print(\"Starting training...\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "history = trainer.train(\n",
    "    train_data=(data['X_train'], data['y_train']),\n",
    "    val_data=(data['X_val'], data['y_val'])\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"Training completed!\")\n",
    "print(f\"Best validation IC: {trainer.best_val_ic:.4f}\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "save_section"
   },
   "source": [
    "## Save Results to Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "save_results"
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# Create timestamped directory\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "run_dir = os.path.join(OUTPUT_DIR, f'run_{timestamp}')\n",
    "os.makedirs(run_dir, exist_ok=True)\n",
    "\n",
    "print(f\"Saving results to: {run_dir}\")\n",
    "\n",
    "# Copy checkpoints\n",
    "checkpoint_dir = os.path.join(run_dir, 'checkpoints')\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "if os.path.exists('checkpoints/best_model.pt'):\n",
    "    shutil.copy('checkpoints/best_model.pt', checkpoint_dir)\n",
    "    print(\"✓ Saved best_model.pt\")\n",
    "if os.path.exists('checkpoints/final_model.pt'):\n",
    "    shutil.copy('checkpoints/final_model.pt', checkpoint_dir)\n",
    "    print(\"✓ Saved final_model.pt\")\n",
    "\n",
    "# Copy logs\n",
    "log_dir = os.path.join(run_dir, 'logs')\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "if os.path.exists('logs/training_history.json'):\n",
    "    shutil.copy('logs/training_history.json', log_dir)\n",
    "    print(\"✓ Saved training_history.json\")\n",
    "\n",
    "# Save training summary\n",
    "summary = {\n",
    "    'timestamp': timestamp,\n",
    "    'device': str(device),\n",
    "    'best_val_ic': float(trainer.best_val_ic),\n",
    "    'total_epochs': trainer.current_epoch,\n",
    "    'config': config,\n",
    "    'model_parameters': model.count_parameters(),\n",
    "    'dataset_info': {\n",
    "        'train_samples': len(data['X_train']),\n",
    "        'val_samples': len(data['X_val']),\n",
    "        'test_samples': len(data['X_test']),\n",
    "        'n_stocks': len(data['stock_symbols']),\n",
    "        'n_features': len(data['feature_names'])\n",
    "    }\n",
    "}\n",
    "\n",
    "summary_path = os.path.join(run_dir, 'training_summary.json')\n",
    "with open(summary_path, 'w') as f:\n",
    "    json.dump(summary, f, indent=2)\n",
    "print(\"✓ Saved training_summary.json\")\n",
    "\n",
    "print(f\"\\n✅ All results saved to Google Drive: {run_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "visualization_section"
   },
   "source": [
    "## Visualize Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "plot_training"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "\n",
    "# Load training history\n",
    "with open('logs/training_history.json', 'r') as f:\n",
    "    history = json.load(f)\n",
    "\n",
    "# Plot training loss\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Training Loss\n",
    "axes[0, 0].plot(history['train_loss'])\n",
    "axes[0, 0].set_title('Training Loss', fontsize=14, fontweight='bold')\n",
    "axes[0, 0].set_xlabel('Epoch')\n",
    "axes[0, 0].set_ylabel('Loss')\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Validation IC\n",
    "val_epochs = [i * config['evaluation']['report_every'] for i in range(len(history['val_metrics']))]\n",
    "val_ics = [m['IC'] for m in history['val_metrics']]\n",
    "axes[0, 1].plot(val_epochs, val_ics, marker='o')\n",
    "axes[0, 1].axhline(y=trainer.best_val_ic, color='r', linestyle='--', label=f'Best: {trainer.best_val_ic:.4f}')\n",
    "axes[0, 1].set_title('Validation IC', fontsize=14, fontweight='bold')\n",
    "axes[0, 1].set_xlabel('Epoch')\n",
    "axes[0, 1].set_ylabel('IC')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Learning Rate\n",
    "axes[1, 0].plot(history['learning_rates'])\n",
    "axes[1, 0].set_title('Learning Rate Schedule', fontsize=14, fontweight='bold')\n",
    "axes[1, 0].set_xlabel('Epoch')\n",
    "axes[1, 0].set_ylabel('LR')\n",
    "axes[1, 0].set_yscale('log')\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Validation Metrics\n",
    "val_acc = [m['Accuracy'] for m in history['val_metrics']]\n",
    "axes[1, 1].plot(val_epochs, val_acc, marker='s', label='Accuracy')\n",
    "if 'ICIR' in history['val_metrics'][0]:\n",
    "    val_icir = [m.get('ICIR', 0) for m in history['val_metrics']]\n",
    "    axes[1, 1].plot(val_epochs, val_icir, marker='^', label='ICIR')\n",
    "axes[1, 1].set_title('Validation Metrics', fontsize=14, fontweight='bold')\n",
    "axes[1, 1].set_xlabel('Epoch')\n",
    "axes[1, 1].set_ylabel('Value')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(run_dir, 'training_curves.png'), dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Training curves saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "validation_section"
   },
   "source": [
    "## Validation Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eval_validation"
   },
   "outputs": [],
   "source": [
    "from src.evaluation.metrics import compute_all_metrics\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Load best model\n",
    "checkpoint = torch.load('checkpoints/best_model.pt', map_location=device)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "print(f\"Loaded best model from epoch {checkpoint['epoch']}\")\n",
    "\n",
    "# Apply EMA weights\n",
    "trainer.ema.shadow = checkpoint['ema_shadow']\n",
    "trainer.ema.apply_shadow()\n",
    "\n",
    "# Generate predictions on validation set\n",
    "model.eval()\n",
    "val_predictions = []\n",
    "val_targets = []\n",
    "\n",
    "val_dataset = TensorDataset(\n",
    "    torch.FloatTensor(data['X_val']),\n",
    "    torch.FloatTensor(data['y_val'])\n",
    ")\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "print(\"Generating validation predictions...\")\n",
    "with torch.no_grad():\n",
    "    for X_batch, y_batch in val_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "        \n",
    "        pred, unc = model(X_batch, R_mask.to(device), n_samples=50)\n",
    "        \n",
    "        val_predictions.append(pred.cpu().numpy())\n",
    "        val_targets.append(y_batch.cpu().numpy())\n",
    "\n",
    "val_predictions = np.concatenate(val_predictions, axis=0)\n",
    "val_targets = np.concatenate(val_targets, axis=0)\n",
    "\n",
    "# Compute metrics\n",
    "val_metrics = compute_all_metrics(val_predictions, val_targets)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"Validation Results\")\n",
    "print(\"=\" * 80)\n",
    "for metric, value in val_metrics.items():\n",
    "    print(f\"{metric:.<30} {value:.4f}\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Save validation results\n",
    "np.savez(\n",
    "    os.path.join(run_dir, 'validation_results.npz'),\n",
    "    predictions=val_predictions,\n",
    "    targets=val_targets,\n",
    "    dates=data['dates_val']\n",
    ")\n",
    "\n",
    "with open(os.path.join(run_dir, 'validation_metrics.json'), 'w') as f:\n",
    "    json.dump({k: float(v) for k, v in val_metrics.items()}, f, indent=2)\n",
    "\n",
    "print(\"\\n✓ Validation results saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "test_section"
   },
   "source": [
    "## Test Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eval_test"
   },
   "outputs": [],
   "source": [
    "# Generate predictions on test set\n",
    "test_predictions = []\n",
    "test_targets = []\n",
    "test_uncertainties = []\n",
    "\n",
    "test_dataset = TensorDataset(\n",
    "    torch.FloatTensor(data['X_test']),\n",
    "    torch.FloatTensor(data['y_test'])\n",
    ")\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "print(\"Generating test predictions...\")\n",
    "with torch.no_grad():\n",
    "    for X_batch, y_batch in test_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "        \n",
    "        pred, unc = model(X_batch, R_mask.to(device), n_samples=50)\n",
    "        \n",
    "        test_predictions.append(pred.cpu().numpy())\n",
    "        test_targets.append(y_batch.cpu().numpy())\n",
    "        test_uncertainties.append(unc.cpu().numpy())\n",
    "\n",
    "test_predictions = np.concatenate(test_predictions, axis=0)\n",
    "test_targets = np.concatenate(test_targets, axis=0)\n",
    "test_uncertainties = np.concatenate(test_uncertainties, axis=0)\n",
    "\n",
    "# Compute metrics\n",
    "test_metrics = compute_all_metrics(test_predictions, test_targets)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"Test Results\")\n",
    "print(\"=\" * 80)\n",
    "for metric, value in test_metrics.items():\n",
    "    print(f\"{metric:.<30} {value:.4f}\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Save test results\n",
    "np.savez(\n",
    "    os.path.join(run_dir, 'test_results.npz'),\n",
    "    predictions=test_predictions,\n",
    "    targets=test_targets,\n",
    "    uncertainties=test_uncertainties,\n",
    "    dates=data['dates_test'],\n",
    "    stock_symbols=data['stock_symbols']\n",
    ")\n",
    "\n",
    "with open(os.path.join(run_dir, 'test_metrics.json'), 'w') as f:\n",
    "    json.dump({k: float(v) for k, v in test_metrics.items()}, f, indent=2)\n",
    "\n",
    "print(\"\\n✓ Test results saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "backtest_section"
   },
   "source": [
    "## Backtesting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "run_backtest"
   },
   "outputs": [],
   "source": [
    "from src.evaluation.backtester import IndianMarketBacktester\n",
    "\n",
    "# Run backtest on test set\n",
    "backtester = IndianMarketBacktester(\n",
    "    predictions=test_predictions,\n",
    "    actuals=test_targets,\n",
    "    dates=data['dates_test'],\n",
    "    stock_symbols=data['stock_symbols'].tolist(),\n",
    "    transaction_costs=config['evaluation']['transaction_costs']\n",
    ")\n",
    "\n",
    "print(\"Running backtest...\")\n",
    "results = backtester.run_topk_strategy(\n",
    "    K=config['evaluation']['top_k'],\n",
    "    rebalance_freq=config['evaluation']['rebalance_freq']\n",
    ")\n",
    "\n",
    "# Print summary\n",
    "backtester.print_backtest_summary(results)\n",
    "\n",
    "# Save backtest results\n",
    "np.savez(\n",
    "    os.path.join(run_dir, 'backtest_results.npz'),\n",
    "    portfolio_values=results['portfolio_values'],\n",
    "    daily_returns=results['daily_returns']\n",
    ")\n",
    "\n",
    "backtest_summary = {\n",
    "    'total_return': float(results['total_return']),\n",
    "    'annualized_return': float(results['annualized_return']),\n",
    "    'sharpe_ratio': float(results['sharpe_ratio']),\n",
    "    'max_drawdown': float(results['max_drawdown']),\n",
    "    'win_rate': float(results['win_rate']),\n",
    "    'avg_turnover': float(results['avg_turnover'])\n",
    "}\n",
    "\n",
    "with open(os.path.join(run_dir, 'backtest_summary.json'), 'w') as f:\n",
    "    json.dump(backtest_summary, f, indent=2)\n",
    "\n",
    "print(\"\\n✓ Backtest results saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "viz_backtest"
   },
   "source": [
    "## Visualize Backtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "plot_backtest"
   },
   "outputs": [],
   "source": [
    "# Plot portfolio performance\n",
    "fig, axes = plt.subplots(2, 1, figsize=(15, 10))\n",
    "\n",
    "# Portfolio value\n",
    "dates = data['dates_test']\n",
    "axes[0].plot(dates, results['portfolio_values'], linewidth=2, color='steelblue')\n",
    "axes[0].axhline(y=1000000, color='gray', linestyle='--', alpha=0.5, label='Initial Capital')\n",
    "axes[0].set_title('Portfolio Value Over Time', fontsize=14, fontweight='bold')\n",
    "axes[0].set_ylabel('Value (₹)')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "axes[0].set_xlim(dates[0], dates[-1])\n",
    "\n",
    "# Daily returns\n",
    "axes[1].bar(dates, results['daily_returns'], width=1, color=['green' if r > 0 else 'red' for r in results['daily_returns']], alpha=0.6)\n",
    "axes[1].axhline(y=0, color='black', linestyle='-', linewidth=0.8)\n",
    "axes[1].set_title('Daily Returns', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel('Date')\n",
    "axes[1].set_ylabel('Return')\n",
    "axes[1].grid(True, alpha=0.3, axis='y')\n",
    "axes[1].set_xlim(dates[0], dates[-1])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(run_dir, 'backtest_performance.png'), dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Backtest visualization saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "final_report"
   },
   "source": [
    "## Final Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "generate_report"
   },
   "outputs": [],
   "source": [
    "# Generate comprehensive report\n",
    "report = f\"\"\"\n",
    "{'='*80}\n",
    "DIFFSTOCK INDIA - TRAINING & EVALUATION REPORT\n",
    "{'='*80}\n",
    "\n",
    "Run ID: {timestamp}\n",
    "Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
    "\n",
    "DATASET\n",
    "{'-'*80}\n",
    "Train samples: {len(data['X_train']):,}\n",
    "Val samples: {len(data['X_val']):,}\n",
    "Test samples: {len(data['X_test']):,}\n",
    "Stocks: {len(data['stock_symbols'])}\n",
    "Features: {len(data['feature_names'])}\n",
    "\n",
    "MODEL\n",
    "{'-'*80}\n",
    "Architecture: DiffSTOCK (MaTCHS + Adaptive DDPM)\n",
    "Parameters: {model.count_parameters()['Total']:,}\n",
    "d_model: {config['model']['d_model']}\n",
    "Diffusion steps: {config['model']['diffusion_T']}\n",
    "\n",
    "TRAINING\n",
    "{'-'*80}\n",
    "Device: {device}\n",
    "Epochs trained: {trainer.current_epoch}\n",
    "Best validation IC: {trainer.best_val_ic:.4f}\n",
    "Batch size: {config['training']['batch_size']}\n",
    "Learning rate: {config['training']['learning_rate']}\n",
    "\n",
    "VALIDATION RESULTS\n",
    "{'-'*80}\n",
    "IC: {val_metrics['IC']:.4f}\n",
    "ICIR: {val_metrics.get('ICIR', 0):.4f}\n",
    "Accuracy: {val_metrics['Accuracy']:.4f}\n",
    "MCC: {val_metrics['MCC']:.4f}\n",
    "\n",
    "TEST RESULTS\n",
    "{'-'*80}\n",
    "IC: {test_metrics['IC']:.4f}\n",
    "ICIR: {test_metrics.get('ICIR', 0):.4f}\n",
    "Accuracy: {test_metrics['Accuracy']:.4f}\n",
    "MCC: {test_metrics['MCC']:.4f}\n",
    "\n",
    "BACKTEST RESULTS (Top-{config['evaluation']['top_k']} Strategy)\n",
    "{'-'*80}\n",
    "Total Return: {results['total_return']:.2%}\n",
    "Annualized Return: {results['annualized_return']:.2%}\n",
    "Sharpe Ratio: {results['sharpe_ratio']:.2f}\n",
    "Max Drawdown: {results['max_drawdown']:.2%}\n",
    "Win Rate: {results['win_rate']:.2%}\n",
    "Avg Turnover: {results['avg_turnover']:.2%}\n",
    "\n",
    "FILES SAVED\n",
    "{'-'*80}\n",
    "✓ checkpoints/best_model.pt\n",
    "✓ checkpoints/final_model.pt\n",
    "✓ training_history.json\n",
    "✓ training_summary.json\n",
    "✓ validation_metrics.json\n",
    "✓ validation_results.npz\n",
    "✓ test_metrics.json\n",
    "✓ test_results.npz\n",
    "✓ backtest_summary.json\n",
    "✓ backtest_results.npz\n",
    "✓ training_curves.png\n",
    "✓ backtest_performance.png\n",
    "\n",
    "LOCATION\n",
    "{'-'*80}\n",
    "Google Drive: {run_dir}\n",
    "\n",
    "{'='*80}\n",
    "Report generated successfully!\n",
    "{'='*80}\n",
    "\"\"\"\n",
    "\n",
    "print(report)\n",
    "\n",
    "# Save report\n",
    "with open(os.path.join(run_dir, 'REPORT.txt'), 'w') as f:\n",
    "    f.write(report)\n",
    "\n",
    "print(f\"\\n✅ Complete report saved to: {os.path.join(run_dir, 'REPORT.txt')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "download_section"
   },
   "source": [
    "## Download Results (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "download_results"
   },
   "outputs": [],
   "source": [
    "# Create zip file of all results\n",
    "import zipfile\n",
    "\n",
    "zip_path = f'/content/diffstock_results_{timestamp}.zip'\n",
    "\n",
    "with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "    for root, dirs, files in os.walk(run_dir):\n",
    "        for file in files:\n",
    "            file_path = os.path.join(root, file)\n",
    "            arcname = os.path.relpath(file_path, run_dir)\n",
    "            zipf.write(file_path, arcname)\n",
    "\n",
    "print(f\"Created zip file: {zip_path}\")\n",
    "print(f\"Size: {os.path.getsize(zip_path) / 1e6:.2f} MB\")\n",
    "\n",
    "# Download\n",
    "files.download(zip_path)\n",
    "print(\"\\n✓ Download started!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tuning_section"
   },
   "source": [
    "## Hyperparameter Tuning Suggestions\n",
    "\n",
    "Based on the results, consider tuning:\n",
    "\n",
    "### If IC is low (<0.03):\n",
    "- Increase `d_model` (128 → 192 or 256)\n",
    "- Increase `n_layers_mrt` (3 → 4 or 5)\n",
    "- Reduce `dropout` (0.25 → 0.15)\n",
    "- Increase `lookback_window` (20 → 30)\n",
    "\n",
    "### If overfitting (val IC >> test IC):\n",
    "- Increase `dropout` (0.25 → 0.35)\n",
    "- Increase `weight_decay` (0.005 → 0.01)\n",
    "- Increase `noise_augmentation` (0.03 → 0.05)\n",
    "- Reduce model size\n",
    "\n",
    "### If training is unstable:\n",
    "- Reduce `learning_rate` (0.0003 → 0.0001)\n",
    "- Increase `warmup_steps` (1000 → 2000)\n",
    "- Reduce `batch_size` (32 → 16)\n",
    "\n",
    "### Edit `config/config.yaml` and retrain!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "conclusion"
   },
   "source": [
    "## Next Steps\n",
    "\n",
    "1. **Analyze Results**: Review metrics in Google Drive\n",
    "2. **Tune Hyperparameters**: Adjust config and retrain\n",
    "3. **Ensemble Models**: Train multiple models with different seeds\n",
    "4. **Feature Engineering**: Add more technical indicators\n",
    "5. **Production Deployment**: Integrate with broker API\n",
    "\n",
    "**All results are saved in your Google Drive!**\n",
    "\n",
    "---\n",
    "\n",
    "**Notebook created by**: Siddhartha Koppaka  \n",
    "**Model**: DiffSTOCK (ICASSP 2024) for Indian Markets  \n",
    "**Repository**: https://github.com/SiddarthaKoppaka/stock_model"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}